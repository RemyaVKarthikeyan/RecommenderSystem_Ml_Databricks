{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd32a39-3eb8-4dc8-aba7-bc55af970f8d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Instruction: Upload steam_200k.csv to DBFS File system and then run the codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f80e5f4-8246-4deb-b92c-7343225b6b91",
     "showTitle": true,
     "title": "Library installation"
    }
   },
   "source": [
    "Installing matplotlib, seaborn, pandas, and plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01fadcff-c683-4910-9607-89118d8967aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "pip install matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434e565a-9c5e-49e7-b6c1-46632875115c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "784a57d0-6ab4-449d-af3b-1e4d047e7216",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729a611f-a0ba-436c-9ad4-446b16756655",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import mlflow and autolog machine learning runs\n",
    "import mlflow\n",
    "mlflow.pyspark.ml.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7615cb1-70a7-4d37-a2fd-dd6eb2bc5d3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f22a53-a3d9-487a-b558-03b4e832a93c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV file into a Spark DataFrame, inferring data types and without a header row\n",
    "steam = spark.read.csv(\"/FileStore/tables/steam_200k.csv\", header=False, inferSchema=True)\n",
    "\n",
    "# Rename the columns to the desired headers\n",
    "steam = steam.toDF(\"ID\", \"game_Name\", \"mem_Type\", \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca0cc441-9292-436f-8247-74811188db36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with any missing values (NaN) from the DataFrame and then display the first 20 rows\n",
    "steam = steam.dropna()\n",
    "steam.show(truncate= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2e05d6-5a98-414e-8008-b836230cf781",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a dataframe containing the distinct game names from steam dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d79789d-80c0-46b0-989b-e1deb1659c11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Step 1: Select the game_Name column and get distinct game names\n",
    "distinct_games_df = steam.select(\"game_Name\").distinct()\n",
    "\n",
    "# Step 2: Add a game_ID column with self-generated numbering starting from 1\n",
    "distinct_games_df = distinct_games_df.withColumn(\n",
    "    \"game_ID\", (monotonically_increasing_id() + 1).cast(\"int\")\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "distinct_games_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba80ee53-8855-48d9-af20-650d3881e0d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the count of distinct games in the distinct_games_df DataFrame\n",
    "distinct_game_count = distinct_games_df.count()\n",
    "\n",
    "# Display the count of distinct games\n",
    "print(f\"Total number of distinct games in distinct_games_df: {distinct_game_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac047f63-2126-4d5c-9517-37f3a826415d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the last 20 rows of the DataFrame\n",
    "last_20_rows = distinct_games_df.tail(20)\n",
    "\n",
    "# Display the last 20 rows\n",
    "for row in last_20_rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eef9346c-7153-429d-aed6-0241184525b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Initial exploratory analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97188a9a-b7ef-4d03-af66-d7bfe76eaa56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View the schema of the DataFrame\n",
    "print(\"\\nSchema of the steam DataFrame:\")\n",
    "steam.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dab9c75-e587-4fc7-aed1-549458d3614d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the total number of rows in the DataFrame\n",
    "total_rows = steam.count()\n",
    "print(f\"\\nTotal number of rows in the steam DataFrame: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b061893f-1343-4d84-bce1-5cc05027d500",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get unique values in mem_Type and game_Name\n",
    "print(\"\\nUnique values in the mem_Type column:\")\n",
    "steam.select(\"mem_Type\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fc31b12-9dca-4d31-8c07-4930890cbc48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nUnique values in the game_Name column:\")\n",
    "steam.select(\"game_Name\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b855c31-a81b-48f6-ac45-c048f5773a21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by mem_Type and count the number of rows in each group\n",
    "print(\"\\nGroup by mem_Type and count the number of rows in each group:\")\n",
    "steam.groupBy(\"mem_Type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52342ec3-5317-4a8c-8388-0916d05fa8d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where mem_Type is \"purchase\"\n",
    "purchase_df = steam.filter(steam.mem_Type == \"purchase\")\n",
    "purchase_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "371922f3-c4a0-48d2-95e7-49c41609a6c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group the filtered DataFrame by game_Name and count the occurrences\n",
    "purchase_count_df = purchase_df.groupBy(\"game_Name\").count()\n",
    "\n",
    "purchase_count_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c10e7ee2-d306-4bf1-821c-eea1bea246d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the purchase_count_df DataFrame to a Pandas DataFrame\n",
    "purchase_count_pandas_df = purchase_count_df.toPandas()\n",
    "\n",
    "# Sort the DataFrame in descending order based on the count\n",
    "purchase_count_pandas_df = purchase_count_pandas_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Select the top 5 rows (top 5 games with the highest number of purchases)\n",
    "top_5_games = purchase_count_pandas_df.head(5)\n",
    "\n",
    "# Plot a vertical bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='game_Name', y='count', data=top_5_games, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Game Name')\n",
    "plt.ylabel('Count of Purchases')\n",
    "plt.title('Top 5 Games with the Highest Number of Purchases')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ba087c-08e0-45b8-8eae-aacb476ccf5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the results in descending order based on the count\n",
    "ordered_purchase_count_df = purchase_count_df.orderBy(\"count\", ascending=False)\n",
    "ordered_purchase_count_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a92c6ece-2a0d-4f96-87c3-d3091643ff18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the game_Name with the highest number of \"purchase\" occurrences\n",
    "top_game = ordered_purchase_count_df.first()\n",
    "\n",
    "\n",
    "# Display the game_Name with the highest number of \"purchase\" occurrences and its count\n",
    "print(f\"The game with the highest number of 'purchase' occurrences is: {top_game['game_Name']}, with {top_game['count']} occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c82768-04e1-4d20-9723-2afa6894bb63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Filter the DataFrame to include only rows where mem_Type is \"play\"\n",
    "play_df = steam.filter(steam.mem_Type == \"play\")\n",
    "play_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3e0957-8c91-4476-9198-e630e33bf557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, round\n",
    "\n",
    "# Group the filtered DataFrame by ID and calculate the cumulative play time (sum of 'value' column)\n",
    "cumulative_play_time_df = play_df.groupBy(\"ID\").agg(sum(\"value\").alias(\"cumulative_play_time\"))\n",
    "\n",
    "# Round the cumulative_play_time column to two decimal places\n",
    "cumulative_play_time_df = cumulative_play_time_df.withColumn(\"cumulative_play_time\", round(cumulative_play_time_df[\"cumulative_play_time\"], 2))\n",
    "\n",
    "# Display the DataFrame with cumulative play time rounded to two decimal places\n",
    "cumulative_play_time_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352da4f2-54f1-4157-95b4-1b4b081dcc80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Arrange the cumulative_play_time_df DataFrame in descending order of cumulative play time\n",
    "cumulative_play_time_df = cumulative_play_time_df.orderBy(\"cumulative_play_time\", ascending=False)\n",
    "\n",
    "# Display the DataFrame with cumulative play time rounded to two decimal places, ordered in descending order\n",
    "cumulative_play_time_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f995d23-fb86-4459-995f-5daaf31bff79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Take the top 5 IDs from the ordered DataFrame\n",
    "top_5_ids_df = cumulative_play_time_df.limit(5)\n",
    "\n",
    "# Display the top 5 IDs with their corresponding cumulative play time\n",
    "top_5_ids_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ef7f182-fd2f-4fab-9608-8612e966c08e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the top 5 IDs DataFrame to a Pandas DataFrame\n",
    "top_5_ids_pandas_df = top_5_ids_df.toPandas()\n",
    "\n",
    "# Plot a horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y='cumulative_play_time', x='ID', data=top_5_ids_pandas_df, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Member ID')\n",
    "plt.ylabel('Cumulative Play Time (Hours)')\n",
    "plt.title('Top 5 Member IDs with Maximum Cumulative Play Time')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41471df-4587-444e-82ff-297a2f3a77cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Giving distinct game_ID to the games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75e78b95-13fe-414b-886f-a55886955971",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, sum, count\n",
    "\n",
    "# Join the steam and distinct_games_df DataFrames on the game name (game_Name)\n",
    "joined_df = steam.join(distinct_games_df, steam[\"game_Name\"] == distinct_games_df[\"game_Name\"], \"inner\")\n",
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "012c0872-0360-4977-b657-212246b7bffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the steam and distinct_games_df DataFrames on the game name (game_Name)\n",
    "joined_df = steam.join(distinct_games_df, steam[\"game_Name\"] == distinct_games_df[\"game_Name\"], \"inner\")\n",
    "\n",
    "# Drop the game_Name column from the joined DataFrame\n",
    "joined_df = joined_df.drop(steam[\"game_Name\"])\n",
    "\n",
    "# Display the joined DataFrame without the game_Name column repetition\n",
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af8cce1c-2768-49f9-bcd1-40ae86bc41fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the distribution of mem_Type\n",
    "mem_type_distribution = joined_df.groupBy(\"mem_Type\").count().toPandas()\n",
    "print(\"\\nDistribution of mem_Type:\")\n",
    "print(mem_type_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "506f84b6-dc80-4f83-925e-31d4023b5a80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of games\n",
    "game_distribution = joined_df.groupBy(\"game_ID\").count().orderBy(desc(\"count\")).toPandas()\n",
    "print(\"\\nTop 10 most frequent games:\")\n",
    "print(game_distribution.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6130e82-daaf-45e2-8ab6-f4439ce471e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of games\n",
    "game_distribution = joined_df.groupBy(\"game_Name\").count().orderBy(desc(\"count\")).toPandas()\n",
    "print(\"\\nTop 10 most frequent games:\")\n",
    "print(game_distribution.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9675e1fe-da5b-46c1-a986-3fac9caaa32c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top games in terms of play time\n",
    "top_games_play_time = joined_df.filter(joined_df[\"mem_Type\"] == \"play\")\\\n",
    "                               .groupBy(\"game_Name\")\\\n",
    "                               .agg(sum(\"value\").alias(\"total_play_time\"))\\\n",
    "                               .orderBy(desc(\"total_play_time\"))\\\n",
    "                               .toPandas()\n",
    "\n",
    "print(\"\\nTop 10 games by play time:\")\n",
    "print(top_games_play_time.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef048785-7af3-464b-a778-53c36d98bfc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the relationship between total play time and total purchases for each game\n",
    "play_vs_purchases_df = joined_df.groupBy(\"game_ID\")\\\n",
    "                                .agg(sum(\"value\").alias(\"total_play_time\"), count(\"ID\").alias(\"total_purchases\"))\n",
    "\n",
    "# Convert to Pandas for plotting\n",
    "play_vs_purchases_df_pandas = play_vs_purchases_df.toPandas()\n",
    "\n",
    "# Plot the relationship between total play time and total purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='total_play_time', y='total_purchases', data=play_vs_purchases_df_pandas)\n",
    "plt.xlabel(\"Total Play Time\")\n",
    "plt.ylabel(\"Total Purchases\")\n",
    "plt.title(\"Total Play Time vs Total Purchases for Each Game ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6302879f-6a41-4f6b-8311-1dbc6f44cafc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import sum, count\n",
    "\n",
    "# Aggregate the data by game name and calculate total play time and total purchases\n",
    "game_aggregated_df = joined_df.groupBy(\"game_Name\")\\\n",
    "                              .agg(sum(\"value\").alias(\"total_play_time\"), count(\"ID\").alias(\"total_purchases\"))\n",
    "\n",
    "# Convert the aggregated DataFrame to a Pandas DataFrame\n",
    "game_aggregated_df_pandas = game_aggregated_df.toPandas()\n",
    "\n",
    "# Calculate the correlation matrix between total play time and total purchases\n",
    "correlation_matrix = game_aggregated_df_pandas[['total_play_time', 'total_purchases']].corr()\n",
    "\n",
    "# Plot the correlation heat map\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True, fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap: Total Play Time and Total Purchases\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea7f0ef-1cd7-42f9-a979-df61c13e5476",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to Pandas for plotting\n",
    "play_vs_purchases_df_pandas = play_vs_purchases_df.toPandas()\n",
    "\n",
    "# Create a hexbin plot to visualize the relationship between total play time and total purchases\n",
    "plt.figure(figsize=(10, 6))\n",
    "hexbin_plot = plt.hexbin(play_vs_purchases_df_pandas['total_play_time'], play_vs_purchases_df_pandas['total_purchases'], gridsize=20, cmap='Oranges', mincnt=1)\n",
    "\n",
    "# Add a color bar to the plot for reference\n",
    "plt.colorbar(hexbin_plot)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Total Play Time\")\n",
    "plt.ylabel(\"Total Purchases\")\n",
    "plt.title(\"Hexbin Plot of Total Play Time vs Total Purchases for Each Game ID\")\n",
    "\n",
    "# Set the x-axis range to display only up to 50,000\n",
    "plt.xlim(0, 50000)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e88950-705a-4799-a432-4891b71a012c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Register the DataFrame as a temporary table\n",
    "joined_df.createOrReplaceTempView(\"joined_df\")\n",
    "\n",
    "# Example 2: Calculate the average play time per game and round the time to 2 decimal places\n",
    "avg_play_time_per_game = spark.sql(\"\"\"\n",
    "    SELECT game_ID, ROUND(AVG(value), 2) AS avg_play_time\n",
    "    FROM joined_df\n",
    "    WHERE mem_Type = 'play'\n",
    "    GROUP BY game_ID\n",
    "\"\"\")\n",
    "\n",
    "# Display the results\n",
    "avg_play_time_per_game.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6df5b69-3d8b-4405-a5ea-dc05f78b6dda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Machine Learning Algorithm for \"Purchase\" Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d913358c-2a16-4bc4-b42c-25d2a35e8dd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Steps in ML Algorithm\n",
    "\n",
    "####Step 1: Filter the Data for 'purchase' type\n",
    "####Step 2: Split the data into training (80%) and test (20%) sets\n",
    "####Step 3: Train the ALS model\n",
    "####Step 4: Evaluate the model's performance using the test data\n",
    "####Step 5: Explore some of the resulting recommendations\n",
    "####Step 6: Generate top 5 recommendations for each user\n",
    "####Step 7: Display the first 5 recommendations for each user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f4ee67b-6a1d-46c8-bb6d-3da78da81cf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Filter the Data for 'purchase' type\n",
    "purchase_joined_df = joined_df.filter(col(\"mem_Type\") == \"purchase\")\n",
    "purchase_joined_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef86d199-a037-4562-840d-f9564bd438f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(training,test) = purchase_joined_df.randomSplit([0.8,0.2],seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3afba516-32ff-4030-861a-73143cf8c510",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(maxIter = 5, regParam = 0.01, userCol = \"ID\" , itemCol =\"game_ID\" , ratingCol = \"value\", seed = 100)\n",
    "model=  als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d131c970-004d-4d36-91e1-0f9e841fff54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test).dropna()\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa2614ad-715d-4036-a00a-5aa693cb78da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Order the predictions DataFrame in descending order of ID\n",
    "predictions_sorted = predictions.orderBy(desc(\"ID\"))\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "predictions_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3798d28b-07f1-4610-844e-fbcbed62d33f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the predictions DataFrame in ascending order of game_ID\n",
    "ordered_predictions = predictions.orderBy(\"game_ID\", ascending=True)\n",
    "\n",
    "# Display the ordered DataFrame\n",
    "ordered_predictions.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2edca9-e26f-49e2-89b4-3bd48ea401f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "# Order the predictions DataFrame based on ID in descending order and game_ID in ascending order\n",
    "ordered_predictions = predictions.orderBy(desc(\"ID\"), asc(\"game_ID\"))\n",
    "\n",
    "# Show the ordered predictions\n",
    "ordered_predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac846944-bfca-4f93-83e9-0c5b6792db79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\",labelCol = \"value\",predictionCol = \"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print( \" Root mean square error is = %g\" %rmse)\n",
    "# Create a RegressionEvaluator for MAE\n",
    "evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"Mean absolute error (MAE) is: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dc291ed-a161-4234-b43d-6aba7944402a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the predictions DataFrame based on prediction in descending order\n",
    "ordered_predictions = predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered predictions\n",
    "ordered_predictions.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7233c68-a17a-4e8f-b818-3b781cb13961",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "predictions = predictions.dropna()\n",
    "\n",
    "# Order the predictions DataFrame based on prediction in descending order\n",
    "ordered_predictions = predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered predictions\n",
    "ordered_predictions.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4fba29-35e8-48be-b179-7af128bac344",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_predictions.createOrReplaceTempView(\"myPredictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011a04e4-8076-46a2-900d-297602bd31b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " \n",
    "select ID,game_ID, game_Name, prediction from myPredictions order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "771da41c-351c-4764-8b8a-153c9dd9b614",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select ID,game_ID, game_Name, prediction from myPredictions where game_Name like '%Wars%' order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c163c3ca-9875-4631-b3b5-550aa834f00b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select ID,game_ID, game_Name, prediction from myPredictions where game_ID In ( 18, 24) order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b377c7-d419-4640-a28b-245ac0ee701c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_predictions.orderBy(\"prediction\",ascending=False).limit(10).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ede7c9-b73e-4aa8-b59f-71cc3dfe5e29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_predictions.game_Name.like('%Wars%')).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a080627-2140-4909-ba45-31fc36df767e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function give recommendatons filtered by game name\n",
    "def recommendationsByGameName(name):\n",
    "    filter = '%' + name + '%'\n",
    "    recommendationsList = ordered_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_predictions.game_Name.like(filter)).limit(10).show(truncate=False)\n",
    "    return recommendationsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3620b311-a82d-44bf-a365-c548795ff3ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGameName('Duty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b683bc38-0d74-4e34-92b7-ffdd7203d735",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function give recommendatons filtered by game id\n",
    "def recommendationsByGameID(game_IDs):\n",
    "    # Filter ordered predictions based on provided game_IDs\n",
    "    filtered_predictions = ordered_predictions.filter(ordered_predictions.game_ID.isin(game_IDs))\n",
    "    \n",
    "    # Order by prediction in descending order and limit to top 10 results\n",
    "    top_recommendations = filtered_predictions.orderBy(\"prediction\", ascending=False).limit(10)\n",
    "    \n",
    "    # Show the top recommendations without truncation\n",
    "    top_recommendations.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the top recommendations\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b8eee79-e692-4bde-9b6d-b795804722ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGameID(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517062dc-0a3d-405b-a25b-09b4717d9dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function give recommendatons filtered by user id\n",
    "def recommendationsByUserID(ID):\n",
    "    # Filter ordered predictions based on provided user ID\n",
    "    user_recommendations = ordered_predictions.filter(ordered_predictions.ID == ID)\n",
    "    \n",
    "    # Order the filtered results by prediction in descending order\n",
    "    ordered_user_recommendations = user_recommendations.orderBy(\"prediction\", ascending=False)\n",
    "    \n",
    "    # Show all the recommendations for the user ID without truncation\n",
    "    ordered_user_recommendations.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the recommendations for the user ID\n",
    "    return ordered_user_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb2ffc03-0ed1-4b59-b87a-0d2946ef28d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByUserID(59945701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf373c50-52f0-43bb-8d82-7dc2d1ca4603",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e97ff6a7-4ccd-4bfb-8f68-6c66e569bd8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f28140-c2e3-45ef-8ddc-af04ae33cce6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Function to get game recommendations for a specific user ID and join with game details\n",
    "def gameRecommendationsForUser(user_ID):\n",
    "    # Filter the recommendations for the specific user ID from userRecs\n",
    "    user_recommendations = userRecs.filter(col(\"ID\") == user_ID)\n",
    "    \n",
    "    # Explode the recommendations column to work with each recommendation separately\n",
    "    user_recommendations_exploded = user_recommendations.select(\"ID\", explode(\"recommendations\").alias(\"recommendation\"))\n",
    "    \n",
    "    # Join the exploded recommendations with the distinct games DataFrame\n",
    "    # Use the game_ID from the recommendations and the distinct_games_df DataFrame to join\n",
    "    recommended_games = user_recommendations_exploded.join(distinct_games_df,\n",
    "                                                          user_recommendations_exploded[\"recommendation.game_ID\"] == distinct_games_df[\"game_ID\"],\n",
    "                                                          how=\"inner\")\\\n",
    "                                                     .select(\"game_ID\", \"game_Name\", \"recommendation.rating\")\\\n",
    "                                                     .orderBy(col(\"recommendation.rating\").desc())\n",
    "    \n",
    "    # Display the recommended games with their ratings (predictions)\n",
    "    recommended_games.show(truncate=False)\n",
    "    \n",
    "    return recommended_games\n",
    "\n",
    "# Call the function for a specific user ID (e.g., user ID = 1)\n",
    "gameRecommendationsForUser(76767)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589ca592-2fd0-4b13-a462-c245d54ffd6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gameRecommendationsForUser(109323647)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf3cecc4-72be-475b-a163-900c22df7548",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Step 1: Take a sample of the training data\n",
    "# Choose a fraction of the data you want to sample (e.g., 0.1 for 10% of the data)\n",
    "sample_fraction = 0.1\n",
    "sample_training = training.sample(False, sample_fraction, seed=42)\n",
    "\n",
    "# Step 2: Perform hyperparameter tuning using the sample of the training data\n",
    "\n",
    "# Create an ALS model instance\n",
    "als = ALS(userCol=\"ID\", itemCol=\"game_ID\", ratingCol=\"value\", coldStartStrategy=\"drop\", seed=42)\n",
    "\n",
    "# Define a regression evaluator for the ALS model\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a parameter grid for ALS model tuning with a smaller range of values\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, [5, 10 ])\\\n",
    "    .addGrid(als.regParam, [0.01, 0.1])\\\n",
    "    .addGrid(als.alpha, [0.1, 0.5])\\\n",
    "    .addGrid(als.maxIter, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "# Define TrainValidationSplit for model tuning\n",
    "tvs = TrainValidationSplit()\\\n",
    "    .setSeed(42)\\\n",
    "    .setTrainRatio(0.75)\\\n",
    "    .setEstimatorParamMaps(param_grid)\\\n",
    "    .setEstimator(als)\\\n",
    "    .setEvaluator(evaluator)\n",
    "\n",
    "# Fit the TrainValidationSplit model with the sample training data\n",
    "gridsearch_model = tvs.fit(sample_training)\n",
    "\n",
    "# Step 3: Use the best model for making predictions and further evaluation\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = gridsearch_model.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "672b0730-d83c-4bd4-aaa4-694446dc4dfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the best model directly for making predictions on the full training data\n",
    "# You do not need to refit the model on the full training data as the model is already trained\n",
    "\n",
    "# Make predictions on the full training data\n",
    "full_training_predictions = best_model.transform(training)\n",
    "\n",
    "# Evaluate the model on the full training data\n",
    "full_training_rmse = evaluator.evaluate(full_training_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on full training data: {full_training_rmse}\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full training data using MAE\n",
    "full_training_mae = evaluator.evaluate(full_training_predictions)\n",
    "print(f\"Mean Absolute Error (MAE) on full training data: {full_training_mae}\")\n",
    "\n",
    "# If you want to use the model on other data for predictions, you can use `best_model` directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629fb989-ab77-4526-9624-376077f9cf57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select best model and identify the parameters\n",
    "bestModel = gridsearch_model.bestModel\n",
    "\n",
    "print(\"Parameters for the best model:\")\n",
    "print(\"Rank Parameter: %g\" % bestModel.rank)\n",
    "print(\"RegParam Parameter: %g\" % bestModel._java_obj.parent().getRegParam())\n",
    "print(\"MaxIter Parameter: %g\" % bestModel._java_obj.parent().getMaxIter())\n",
    "print(\"ImplicitPrefs Parameter: %s\" % bestModel._java_obj.parent().getImplicitPrefs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16075f23-6fba-4bbf-b32b-a888f0a3f07f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "full_test_predictions = best_model.transform(test)\n",
    "\n",
    "evaluator.setMetricName(\"rmse\")\n",
    "# Evaluate the model on the full test data\n",
    "full_test_rmse = evaluator.evaluate(full_test_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on full test data: {full_test_rmse}\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full test data using MAE\n",
    "full_test_mae = evaluator.evaluate(full_test_predictions)\n",
    "print(f\"Mean Absolute Error (MAE) on full test data: {full_test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34482dc5-5412-44fe-9903-df727e9e1478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform data with the best model\n",
    "bestGeneratedPredictions = bestModel.transform(test)\n",
    "\n",
    "# Drop rows with null values\n",
    "bestGeneratedPredictions = bestGeneratedPredictions.dropna()\n",
    "\n",
    "# Order predictions in descending order based on the 'prediction' column\n",
    "sorted_predictions = bestGeneratedPredictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Display the top 10 sorted predictions\n",
    "sorted_predictions.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c61eafcf-6de4-4cba-b61b-b453bd97a12c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(sorted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84db2c25-be8a-4843-9d81-5980f1f767d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sorted_predictions_pandas = sorted_predictions.toPandas()\n",
    "print(sorted_predictions_pandas.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50a0466-9687-475a-9286-d531aec682fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "sorted_predictions_pandas = sorted_predictions.toPandas()\n",
    "\n",
    "# Plotting top 10 predictions as a bar chart\n",
    "sns.barplot(data=sorted_predictions_pandas.head(10), x='game_ID', y='prediction')\n",
    "plt.xlabel('Game ID')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('Top 10 Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73638240-d97d-4811-91f5-66635b20f6e8",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert sorted_predictions to Pandas DataFrame\n",
    "sorted_predictions_df = sorted_predictions.toPandas()\n",
    "\n",
    "# Apply color coding to the table using style.background_gradient\n",
    "styled_table = sorted_predictions_df.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# Display the styled table\n",
    "styled_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3803a92c-1b95-4d11-917a-ccc8a18f88df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Machine Learning Algorithm for \"Play\" Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "229fe733-7232-4c75-bf4d-40a9f7549bf6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Filter the data for 'play' type\n",
    "play_joined_df = joined_df.filter(col(\"mem_Type\") == \"play\")\n",
    "\n",
    "# Display the play_joined_df DataFrame\n",
    "play_joined_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a54d0a0-355a-4ee8-a1d0-9494d64a079a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and test (20%) sets\n",
    "(train_play, test_play) = play_joined_df.randomSplit([0.8, 0.2], seed=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a50ed215-5dcf-4218-90e9-4e3ccde6b945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Create an ALS model with specified parameters\n",
    "als_play = ALS(maxIter=5, regParam=0.01, userCol=\"ID\", itemCol=\"game_ID\", ratingCol=\"value\", seed=100)\n",
    "\n",
    "# Fit the model to the training data for the 'play' type\n",
    "play_model = als_play.fit(train_play)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ee76594-7bb2-454d-8df3-28b6e43a7955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the trained model (play_model) to generate predictions on the test data (test_play)\n",
    "play_predictions = play_model.transform(test_play).dropna()\n",
    "\n",
    "# Display the predictions without truncation\n",
    "play_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a061663-a228-4704-b8da-849560a38a33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Order the play_predictions DataFrame in descending order of ID\n",
    "play_predictions_sorted = play_predictions.orderBy(desc(\"ID\"))\n",
    "\n",
    "# Display the sorted DataFrame without truncation\n",
    "play_predictions_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "602011e8-90e4-48ef-8c7b-09a6b7abf5fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the play_predictions DataFrame in ascending order of game_ID\n",
    "ordered_play_predictions = play_predictions.orderBy(\"game_ID\", ascending=True)\n",
    "\n",
    "# Display the ordered DataFrame without truncation\n",
    "ordered_play_predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9487d4a3-bc86-4347-b988-e0aa1af309bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "# Order the play_predictions DataFrame based on ID in descending order and game_ID in ascending order\n",
    "ordered_play_predictions = play_predictions.orderBy(desc(\"ID\"), asc(\"game_ID\"))\n",
    "\n",
    "# Show the ordered play predictions\n",
    "ordered_play_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9e447ba-8847-45e4-b4ea-5661487667bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a RegressionEvaluator for RMSE\n",
    "play_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "\n",
    "# Evaluate the RMSE of play_predictions\n",
    "play_rmse = play_evaluator.evaluate(play_predictions)\n",
    "print(f\"Root Mean Square Error (RMSE) for 'play' predictions is: {play_rmse:.4f}\")\n",
    "\n",
    "# Create a RegressionEvaluator for MAE\n",
    "evaluator_play_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "play_mae = evaluator_play_mae.evaluate(play_predictions)\n",
    "print(f\"Mean absolute error (MAE) is: {play_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a75e4469-8981-4d88-8123-24a4326c8cef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the predictions DataFrame based on prediction in descending order\n",
    "ordered_play_predictions = play_predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered predictions\n",
    "ordered_play_predictions.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7cc2e1-0a86-4fba-9631-21cb586c8359",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values from play_predictions\n",
    "play_predictions = play_predictions.dropna()\n",
    "\n",
    "# Order the play predictions DataFrame based on prediction in descending order\n",
    "ordered_play_predictions = play_predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered play predictions\n",
    "ordered_play_predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75141a53-8d04-43c9-b8ff-922cd6d51fc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_play_predictions.createOrReplaceTempView(\"my_play_Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dfcae84-c000-4ed9-8327-d97f45fbe06c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select ID,game_ID, game_Name, prediction from my_play_Predictions order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab21071-13b5-421e-85c0-ad1659e44cd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select ID,game_ID, game_Name, prediction from my_play_Predictions where game_Name like '%Wars%' order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce7081ed-5266-44ea-8fed-3c8fac20e570",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " select ID,game_ID, game_Name, prediction from my_play_Predictions where game_ID In ( 18, 24) order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9265edd3-6e92-4e95-9790-47bfa380cf8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_play_predictions.orderBy(\"prediction\",ascending=False).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111cb4cf-0bcb-41b3-a0a9-324fe28aedd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_play_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_play_predictions.game_Name.like('%Wars%')).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b10e711-64d3-4798-a7c3-4e48146dbe48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to give recommendation filtered by name\n",
    "def recommendationsByGamePlayName(name):\n",
    "    filter = '%' + name + '%'\n",
    "    recommendationsList = ordered_play_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_play_predictions.game_Name.like(filter)).limit(10).show(truncate=False)\n",
    "    return recommendationsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c86ac50-cf8c-4b2e-ae9c-a21b4a3e54e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGamePlayName('Duty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02aa1302-ef4a-48cc-bbc4-6024b2405b83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to give recommendation filtered by game id\n",
    "def recommendationsByGamePlayID(game_IDs):\n",
    "    # Filter ordered predictions based on provided game_IDs\n",
    "    filtered_play_predictions = ordered_play_predictions.filter(ordered_play_predictions.game_ID.isin(game_IDs))\n",
    "    \n",
    "    # Order by prediction in descending order and limit to top 10 results\n",
    "    top_recommendations_play = filtered_play_predictions.orderBy(\"prediction\", ascending=False).limit(10)\n",
    "    \n",
    "    # Show the top recommendations without truncation\n",
    "    top_recommendations_play.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the top recommendations\n",
    "    return top_recommendations_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40bae1b1-80c7-4073-a390-d05ac15333d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGamePlayID(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "632ae5d5-81e6-4d1f-9e10-b4e4e93fb700",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to give recommendation filtered by user id\n",
    "def recommendationsByUserPlayID(ID):\n",
    "    # Filter ordered predictions based on provided user ID\n",
    "    user_recommendations_play = ordered_play_predictions.filter(ordered_play_predictions.ID == ID)\n",
    "    \n",
    "    # Order the filtered results by prediction in descending order\n",
    "    ordered_user_recommendations_play = user_recommendations_play.orderBy(\"prediction\", ascending=False)\n",
    "    \n",
    "    # Show all the recommendations for the user ID without truncation\n",
    "    ordered_user_recommendations_play.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the recommendations for the user ID\n",
    "    return ordered_user_recommendations_play\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95c1b475-e87e-4879-b61b-14c886bfbf94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByUserPlayID(43908860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e39db1c-4fe9-4bdd-bf82-3a0aa623c5b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs_play = play_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d0330d-0184-4b0e-a826-6da6c92952ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs_play.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a36e94-3d7c-42d4-8ab7-e8d7f132a68d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Function to get game recommendations for a specific user ID and join with game details\n",
    "def gameRecommendationsForUserPlay(user_ID):\n",
    "    # Filter the recommendations for the specific user ID from userRecs\n",
    "    user_recommendationsPlay = userRecs_play.filter(col(\"ID\") == user_ID)\n",
    "    \n",
    "    # Explode the recommendations column to work with each recommendation separately\n",
    "    user_recommendationsPlay_exploded = user_recommendationsPlay.select(\"ID\", explode(\"recommendations\").alias(\"recommendation\"))\n",
    "    \n",
    "    # Join the exploded recommendations with the distinct games DataFrame\n",
    "    # Use the game_ID from the recommendations and the distinct_games_df DataFrame to join\n",
    "    recommended_gamesPlay = user_recommendationsPlay_exploded.join(distinct_games_df,\n",
    "                                                          user_recommendationsPlay_exploded[\"recommendation.game_ID\"] == distinct_games_df[\"game_ID\"],\n",
    "                                                          how=\"inner\")\\\n",
    "                                                     .select(\"game_ID\", \"game_Name\", \"recommendation.rating\")\\\n",
    "                                                     .orderBy(col(\"recommendation.rating\").desc())\n",
    "    \n",
    "    # Display the recommended games with their ratings (predictions)\n",
    "    recommended_gamesPlay.show(truncate=False)\n",
    "    \n",
    "    return recommended_gamesPlay\n",
    "\n",
    "# Call the function for a specific user ID (e.g., user ID = 1)\n",
    "gameRecommendationsForUserPlay(76767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bde1eca4-206d-40ec-840c-a21239255612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gameRecommendationsForUserPlay(109323647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93856e2c-f27f-48d1-8dad-199702939ca9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Step 1: Take a sample of the training data\n",
    "# Choose a fraction of the data you want to sample (e.g., 0.1 for 10% of the data)\n",
    "sample_fraction = 0.1\n",
    "sample_train_play = train_play.sample(False, sample_fraction, seed=42)\n",
    "\n",
    "# Step 2: Perform hyperparameter tuning using the sample of the training data\n",
    "\n",
    "# Create an ALS model instance\n",
    "als = ALS(userCol=\"ID\", itemCol=\"game_ID\", ratingCol=\"value\", coldStartStrategy=\"drop\", seed=42)\n",
    "\n",
    "# Define a regression evaluator for the ALS model\n",
    "evaluator_play = RegressionEvaluator(metricName=\"rmse\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a parameter grid for ALS model tuning with a smaller range of values\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, [5, 10 ])\\\n",
    "    .addGrid(als.regParam, [0.01, 0.1])\\\n",
    "    .addGrid(als.alpha, [0.1, 0.5])\\\n",
    "    .addGrid(als.maxIter, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "# Define TrainValidationSplit for model tuning\n",
    "tvs_play = TrainValidationSplit()\\\n",
    "    .setSeed(42)\\\n",
    "    .setTrainRatio(0.75)\\\n",
    "    .setEstimatorParamMaps(param_grid)\\\n",
    "    .setEstimator(als)\\\n",
    "    .setEvaluator(evaluator_play)\n",
    "\n",
    "# Fit the TrainValidationSplit model with the sample training data\n",
    "gridsearch_model_play = tvs_play.fit(sample_train_play)\n",
    "\n",
    "# Step 3: Use the best model for making predictions and further evaluation\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model_play = gridsearch_model_play.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac9f938e-9440-443a-9be4-2aa295314d83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the best model directly for making predictions on the full training data\n",
    "# You do not need to refit the model on the full training data as the model is already trained\n",
    "\n",
    "# Make predictions on the full training data\n",
    "full_training_predictions_play = best_model_play.transform(train_play)\n",
    "\n",
    "# Evaluate the model on the full training data\n",
    "full_training_rmse_play = evaluator_play.evaluate(full_training_predictions_play)\n",
    "print(f\"Root Mean Squared Error (RMSE) on full training data: {full_training_rmse_play}\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator_play.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full training data using MAE\n",
    "full_training_mae_play = evaluator_play.evaluate(full_training_predictions_play)\n",
    "print(f\"Mean Absolute Error (MAE) on full training data: {full_training_mae_play}\")\n",
    "\n",
    "# If you want to use the model on other data for predictions, you can use `best_model` directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5e2fa1-700e-46f8-849c-d7e63d8251a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select best model and identify the parameters\n",
    "\n",
    "print(\"Parameters for the best model:\")\n",
    "print(\"Rank Parameter: %g\" %best_model_play.rank)\n",
    "print(\"RegParam Parameter: %g\" %best_model_play._java_obj.parent().getRegParam())\n",
    "print(\"MaxIter Parameter: %g\" %best_model_play._java_obj.parent().getMaxIter())\n",
    "print(\"ImplicitPrefs Parameter: %s\" %best_model_play._java_obj.parent().getImplicitPrefs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5102c20c-8a4f-4b4d-9f02-e9f6da0edad0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform the test data using the best model\n",
    "transformed_test_play = best_model_play.transform(test_play)\n",
    "\n",
    "# Ensure that the `prediction` column is of type `double`\n",
    "transformed_test_play = transformed_test_play.withColumn(\n",
    "    \"prediction\",\n",
    "    transformed_test_play[\"prediction\"].cast(\"double\")\n",
    ")\n",
    "\n",
    "# Evaluate the model on the full test data\n",
    "evaluator_play.setMetricName(\"rmse\")\n",
    "full_test_rmse_play = evaluator_play.evaluate(transformed_test_play)\n",
    "print(f\"Root Mean Squared Error (RMSE) on full test data: {full_test_rmse_play}\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator_play.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full test data using MAE\n",
    "full_test_mae_play = evaluator_play.evaluate(transformed_test_play)\n",
    "print(f\"Mean Absolute Error (MAE) on full test data: {full_test_mae_play}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992e02f2-c9f3-4dfe-b9f1-98fb8e0252d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform data with the best model\n",
    "bestGeneratedPlayPredictions = best_model_play.transform(test_play)\n",
    "\n",
    "# Drop rows with null values\n",
    "bestGeneratedPlayPredictions = bestGeneratedPlayPredictions.dropna()\n",
    "\n",
    "# Order predictions in descending order based on the 'prediction' column\n",
    "sorted_predictions_play = bestGeneratedPlayPredictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Display the top 10 sorted predictions\n",
    "sorted_predictions_play.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38e95026-1b27-4566-b26f-335228dbcaf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the sorted predictions\n",
    "sorted_predictions_play.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbfae0c-f981-405e-9d44-b1cbe08b835e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "sorted_predictions_pandas = sorted_predictions_play.toPandas()\n",
    "\n",
    "# Print the top 10 rows\n",
    "print(sorted_predictions_pandas.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5837e437-578d-4067-9064-688ded9546ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "sorted_predictions_pandas = sorted_predictions_play.toPandas()\n",
    "\n",
    "# Plotting top 10 predictions as a bar chart\n",
    "sns.barplot(data=sorted_predictions_pandas.head(10), x='game_ID', y='prediction')\n",
    "plt.xlabel('Game ID')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('Top 10 Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf246f58-8ce4-4b66-b5f2-0790dc56210f",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert sorted_predictions to Pandas DataFrame\n",
    "sorted_predictions_df = sorted_predictions_play.toPandas()\n",
    "\n",
    "# Apply color coding to the table using style.background_gradient\n",
    "styled_table = sorted_predictions_df.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# Display the styled table\n",
    "styled_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6463dd-b948-4be4-b51b-2849cf5fd657",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Machine Learning Algorithm for \"Purchase\" and \"Play\" Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "640021bf-41f0-4ac6-b156-de3410d1b4e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Filter the data for 'play' type\n",
    "purchase_play_df = joined_df.filter(col(\"mem_Type\").isin([\"purchase\", \"play\"]))\n",
    "\n",
    "# Display the play_joined_df DataFrame\n",
    "purchase_play_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f1efa9f-f0e2-407c-b294-69060f1b14a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and test (20%) sets\n",
    "(train_purchase_play, test_purchase_play) = purchase_play_df.randomSplit([0.8, 0.2], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a988b9fe-5224-4f7c-94b1-370ef8bc3bc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Create an ALS model with specified parameters\n",
    "als_purchase_play = ALS(maxIter=5, regParam=0.01, userCol=\"ID\", itemCol=\"game_ID\", ratingCol=\"value\", seed=100)\n",
    "\n",
    "# Fit the model to the training data for the 'play' type\n",
    "purchase_play_model = als_purchase_play.fit(train_purchase_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295212ef-01b3-4f29-9173-47b19f0b08bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the trained model (play_model) to generate predictions on the test data (test_play)\n",
    "purchase_play_predictions = purchase_play_model.transform(test_purchase_play).dropna()\n",
    "\n",
    "# Display the predictions without truncation\n",
    "purchase_play_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0d09913-1909-4b3d-bdb8-39d868af6841",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Order the play_predictions DataFrame in descending order of ID\n",
    "purchase_play_predictions_sorted = purchase_play_predictions.orderBy(desc(\"ID\"))\n",
    "\n",
    "# Display the sorted DataFrame without truncation\n",
    "purchase_play_predictions_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c840d60c-c0d3-4e5c-a2ee-be700deedfc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the play_predictions DataFrame in ascending order of game_ID\n",
    "ordered_purchase_play_predictions = purchase_play_predictions.orderBy(\"game_ID\", ascending=True)\n",
    "\n",
    "# Display the ordered DataFrame without truncation\n",
    "ordered_purchase_play_predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b220505-8bc7-44bd-8f84-5bfcc880ed0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "# Order the play_predictions DataFrame based on ID in descending order and game_ID in ascending order\n",
    "ordered_purchase_play_predictions = purchase_play_predictions.orderBy(desc(\"ID\"), asc(\"game_ID\"))\n",
    "\n",
    "# Show the ordered play predictions\n",
    "ordered_purchase_play_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d1decdd-c846-488b-a356-be1f1c7f7810",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a RegressionEvaluator for RMSE\n",
    "purchase_play_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "\n",
    "# Evaluate the RMSE of play_predictions\n",
    "purchase_play_rmse = purchase_play_evaluator.evaluate(purchase_play_predictions)\n",
    "print(f\"Root Mean Square Error (RMSE) for 'purchase' and play' predictions is: {purchase_play_rmse:.4f}\")\n",
    "\n",
    "purchase_play_evaluator.setMetricName(\"mae\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full training data using MAE\n",
    "purchase_play_mae = purchase_play_evaluator.evaluate(purchase_play_predictions)\n",
    "print(f\"Root Mean Square Error (RMSE) for 'purchase' and play' predictions is: {purchase_play_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be494d7-6dfd-4fe3-8214-875c66b2d3cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order the predictions DataFrame based on prediction in descending order\n",
    "ordered_purchase_play_predictions = purchase_play_predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered predictions\n",
    "ordered_purchase_play_predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ce2440-a229-4102-9a8e-a068397f7108",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values from play_predictions\n",
    "purchase_play_predictions = purchase_play_predictions.dropna()\n",
    "\n",
    "# Order the play predictions DataFrame based on prediction in descending order\n",
    "ordered_purchase_play_predictions = purchase_play_predictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Show the ordered play predictions\n",
    "ordered_purchase_play_predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007957db-1dfe-47e2-bcc4-3f5e1b27bc40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_purchase_play_predictions.createOrReplaceTempView(\"my_purchase_play_Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce6b711-469a-4b6e-b3a3-c1cf0fc7f045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select ID,game_ID, game_Name, prediction from my_purchase_play_Predictions order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b58df5-ffc1-473f-af96-074587016f8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select ID,game_ID, game_Name, prediction from my_purchase_play_Predictions where game_Name like '%Wars%' order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a26b137-a2b8-4d3b-ae4c-7faaa439657a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select ID,game_ID, game_Name, prediction from my_purchase_play_Predictions where game_ID In ( 18, 24) order by prediction desc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "521c3b10-a91d-4b27-a4c7-64072693303f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_purchase_play_predictions.orderBy(\"prediction\",ascending=False).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5dea552-b926-4479-a4d5-47fa136fb9ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ordered_purchase_play_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_purchase_play_predictions.game_Name.like('%Wars%')).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adefdbe1-682a-4449-b69e-db8d9ba6a55a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to get recommendation filtered by game name\n",
    "def recommendationsByGamePurchasePlayName(name):\n",
    "    filter = '%' + name + '%'\n",
    "    recommendationsList = ordered_purchase_play_predictions.orderBy(\"prediction\",ascending=False).filter(ordered_purchase_play_predictions.game_Name.like(filter)).limit(10).show(truncate=False)\n",
    "    return recommendationsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a12e31be-26e4-456e-80eb-53a8ba12565e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGamePurchasePlayName('Duty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c299436-0acf-4cda-9499-ee87fddde443",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to get recommendation filtered by game ID\n",
    "def recommendationsByGamePurchasePlayID(game_IDs):\n",
    "    # Filter ordered predictions based on provided game_IDs\n",
    "    filtered_purchase_play_predictions = ordered_purchase_play_predictions.filter(ordered_purchase_play_predictions.game_ID.isin(game_IDs))\n",
    "    \n",
    "    # Order by prediction in descending order and limit to top 10 results\n",
    "    top_recommendations_purchase_play = filtered_purchase_play_predictions.orderBy(\"prediction\", ascending=False).limit(10)\n",
    "    \n",
    "    # Show the top recommendations without truncation\n",
    "    top_recommendations_purchase_play.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the top recommendations\n",
    "    return top_recommendations_purchase_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49509415-8161-463c-b7c9-1aa4d670d6e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByGamePlayID(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e7c88c-b9b1-446d-b219-08c44e96f9c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Function to get recommendation filtered by user ID\n",
    "def recommendationsByUserPurchasePlayID(ID):\n",
    "    # Filter ordered predictions based on provided user ID\n",
    "    user_recommendations_purchase_play = ordered_purchase_play_predictions.filter(ordered_purchase_play_predictions.ID == ID)\n",
    "    \n",
    "    # Order the filtered results by prediction in descending order\n",
    "    ordered_user_recommendations_purchase_play = user_recommendations_purchase_play.orderBy(\"prediction\", ascending=False)\n",
    "    \n",
    "    # Show all the recommendations for the user ID without truncation\n",
    "    ordered_user_recommendations_purchase_play.show(truncate=False)\n",
    "    \n",
    "    # Return the DataFrame containing the recommendations for the user ID\n",
    "    return ordered_user_recommendations_purchase_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af76423-5c77-4efa-893a-b6041fc1d873",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recommendationsByUserPurchasePlayID(43908860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c6aa93d-9c0c-4acc-840a-7d8b0cd7c014",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs_purchase_play = purchase_play_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6e524e-e187-4381-9405-a69a2b104a99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs_purchase_play.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5e3987-1e32-4bfa-b650-493f00a8feae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Function to get game recommendations for a specific user ID and join with game details\n",
    "def gameRecommendationsForUserPurchasePlay(user_ID):\n",
    "    # Filter the recommendations for the specific user ID from userRecs\n",
    "    user_recommendationspurchase_Play = userRecs_purchase_play.filter(col(\"ID\") == user_ID)\n",
    "    \n",
    "    # Explode the recommendations column to work with each recommendation separately\n",
    "    user_recommendationspurchase_Play_exploded = user_recommendationspurchase_Play.select(\"ID\", explode(\"recommendations\").alias(\"recommendation\"))\n",
    "    \n",
    "    # Join the exploded recommendations with the distinct games DataFrame\n",
    "    # Use the game_ID from the recommendations and the distinct_games_df DataFrame to join\n",
    "    recommended_gamespurchase_Play = user_recommendationspurchase_Play_exploded.join(distinct_games_df,\n",
    "                                                          user_recommendationspurchase_Play_exploded[\"recommendation.game_ID\"] == distinct_games_df[\"game_ID\"],\n",
    "                                                          how=\"inner\")\\\n",
    "                                                     .select(\"game_ID\", \"game_Name\", \"recommendation.rating\")\\\n",
    "                                                     .orderBy(col(\"recommendation.rating\").desc())\n",
    "    \n",
    "    # Display the recommended games with their ratings (predictions)\n",
    "    recommended_gamespurchase_Play.show(truncate=False)\n",
    "    \n",
    "    return recommended_gamespurchase_Play\n",
    "\n",
    "# Call the function for a specific user ID (e.g., user ID = 1)\n",
    "gameRecommendationsForUserPurchasePlay(76767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586e3bb9-7959-45a1-8b2d-856d6be1bd1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gameRecommendationsForUserPurchasePlay(109323647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5a7f82-9c5e-487e-967c-99d6e04447b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Step 1: Take a sample of the training data\n",
    "# Choose a fraction of the data you want to sample (e.g., 0.1 for 10% of the data)\n",
    "sample_fraction = 0.1\n",
    "sample_train_purchase_play = train_purchase_play.sample(False, sample_fraction, seed=42)\n",
    "\n",
    "# Step 2: Perform hyperparameter tuning using the sample of the training data\n",
    "\n",
    "# Create an ALS model instance\n",
    "als = ALS(userCol=\"ID\", itemCol=\"game_ID\", ratingCol=\"value\", coldStartStrategy=\"drop\", seed=42)\n",
    "\n",
    "# Define a regression evaluator for the ALS model\n",
    "evaluator_purchase_play = RegressionEvaluator(metricName=\"rmse\", labelCol=\"value\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a parameter grid for ALS model tuning with a smaller range of values\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, [5, 10])\\\n",
    "    .addGrid(als.regParam, [0.01, 0.1])\\\n",
    "    .addGrid(als.alpha, [0.1, 0.5])\\\n",
    "    .addGrid(als.maxIter, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "# Define TrainValidationSplit for model tuning\n",
    "tvs_purchase_play = TrainValidationSplit()\\\n",
    "    .setSeed(42)\\\n",
    "    .setTrainRatio(0.75)\\\n",
    "    .setEstimatorParamMaps(param_grid)\\\n",
    "    .setEstimator(als)\\\n",
    "    .setEvaluator(evaluator_purchase_play)\n",
    "\n",
    "# Fit the TrainValidationSplit model with the sample training data\n",
    "gridsearch_model_purchase_play = tvs_purchase_play.fit(sample_train_purchase_play)\n",
    "\n",
    "# Step 3: Use the best model for making predictions and further evaluation\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model_purchase_play = gridsearch_model_purchase_play.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf490094-2a7d-4e36-92ca-3b3b2cfe3bb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the best model directly for making predictions on the full training data\n",
    "# Transform the training data using the best model\n",
    "full_training_predictions_purchase_play = best_model_purchase_play.transform(train_purchase_play)\n",
    "\n",
    "# Convert the prediction column to double type, if necessary\n",
    "full_training_predictions_purchase_play = full_training_predictions_purchase_play.withColumn(\n",
    "    \"prediction\",\n",
    "    full_training_predictions_purchase_play[\"prediction\"].cast(\"double\")\n",
    ")\n",
    "# Evaluate the model on the full training data using RMSE\n",
    "evaluator_purchase_play.setMetricName(\"rmse\")\n",
    "full_training_rmse_purchase_play = evaluator_purchase_play.evaluate(full_training_predictions_purchase_play)\n",
    "print(f\"Root Mean Squared Error (RMSE) on full training data: {full_training_rmse_purchase_play}\")\n",
    "\n",
    "# Change the metricName of the evaluator to 'mae' to evaluate Mean Absolute Error (MAE)\n",
    "evaluator_purchase_play.setMetricName(\"mae\")\n",
    "\n",
    "# Evaluate the model on the full training data using MAE\n",
    "full_training_mae_purchase_play = evaluator_purchase_play.evaluate(full_training_predictions_purchase_play)\n",
    "print(f\"Mean Absolute Error (MAE) on full training data: {full_training_mae_purchase_play}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b244d2c-6186-486d-8287-e3bc0d32c307",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select best model and identify the parameters\n",
    "\n",
    "print(\"Parameters for the best model:\")\n",
    "print(\"Rank Parameter: %g\" %best_model_purchase_play.rank)\n",
    "print(\"RegParam Parameter: %g\" %best_model_purchase_play._java_obj.parent().getRegParam())\n",
    "print(\"MaxIter Parameter: %g\" %best_model_purchase_play._java_obj.parent().getMaxIter())\n",
    "print(\"ImplicitPrefs Parameter: %s\" %best_model_purchase_play._java_obj.parent().getImplicitPrefs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5e34e7e-deb1-49d5-b5c4-946bb60a0534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform predictions on the test data using the best model\n",
    "test_predictions_purchase_play = best_model_purchase_play.transform(test_purchase_play)\n",
    "\n",
    "# Convert the prediction column to double type, if necessary\n",
    "test_predictions_purchase_play = test_predictions_purchase_play.withColumn(\n",
    "    \"prediction\",\n",
    "    test_predictions_purchase_play[\"prediction\"].cast(\"double\")\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data using RMSE\n",
    "evaluator_purchase_play.setMetricName(\"rmse\")\n",
    "test_rmse_pp = evaluator_purchase_play.evaluate(test_predictions_purchase_play)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {test_rmse_pp}\")\n",
    "\n",
    "# Evaluate the model on the test data using MAE\n",
    "evaluator_purchase_play.setMetricName(\"mae\")\n",
    "test_mae_pp = evaluator_purchase_play.evaluate(test_predictions_purchase_play)\n",
    "print(f\"Mean Absolute Error (MAE) on test data: {test_mae_pp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a511f6-6c87-4dde-9cae-6ce4a9e5c106",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform data with the best model\n",
    "bestGeneratedPurchasePlayPredictions = best_model_purchase_play.transform(test_purchase_play)\n",
    "\n",
    "# Drop rows with null values\n",
    "bestGeneratedPurchasePlayPredictions = bestGeneratedPurchasePlayPredictions.dropna()\n",
    "\n",
    "# Order predictions in descending order based on the 'prediction' column\n",
    "sorted_predictions_purchase_play = bestGeneratedPurchasePlayPredictions.orderBy(\"prediction\", ascending=False)\n",
    "\n",
    "# Display the top 10 sorted predictions\n",
    "sorted_predictions_purchase_play.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb46f6b-87c2-4bfb-ab0b-fbdd85687f70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the sorted predictions\n",
    "sorted_predictions_purchase_play.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50c45c13-5cd0-47a6-b4ce-eb78dcf17fba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "sorted_predictions_pandas_purchase_play = sorted_predictions_purchase_play.toPandas()\n",
    "\n",
    "# Print the top 10 rows\n",
    "print(sorted_predictions_pandas_purchase_play.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c58b268-34a2-48eb-815a-7f1517187360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "sorted_predictions_pandas_purchase_play = sorted_predictions_purchase_play.toPandas()\n",
    "\n",
    "# Plotting top 10 predictions as a bar chart\n",
    "sns.barplot(data=sorted_predictions_pandas_purchase_play.head(10), x='game_ID', y='prediction')\n",
    "plt.xlabel('Game ID')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('Top 10 Predictions (Purchase Play)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d00a02f1-d810-424e-8c4a-fdf30d6e4978",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert sorted_predictions to Pandas DataFrame\n",
    "sorted_predictions_df_purchase_play = sorted_predictions_purchase_play.toPandas()\n",
    "\n",
    "# Apply color coding to the table using style.background_gradient\n",
    "# Limit the DataFrame to the first 20 rows using the `head()` method\n",
    "styled_table_purchase_play = sorted_predictions_df_purchase_play.head(50).style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# Display the styled table\n",
    "styled_table_purchase_play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7bfbd8-a475-4261-bbdc-d0224f203897",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "POWER BI - DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5527b022-972c-4935-96c4-a60d9b96225e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116d3e76-5a18-486f-ae46-cb6e0444a556",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df.write.mode(\"overwrite\").csv(\"/FileStore/tables/steam_with_game_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb820e6-e808-43a6-82aa-7843fe8dc7ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table if exists steam_with_game_id;\n",
    "create table steam_with_game_id\n",
    "using csv\n",
    "options (path \"dbfs:/FileStore/tables/steam_with_game_id.csv\", header \"False\" , inferSchema \"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c54c54-d92c-4685-8432-ca4bc21a3fa8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c390e2fe-85a0-44d4-ba14-eac34e3a0319",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM steam_with_game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7510d64-e245-4a6d-8b4e-936152e9af3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove all files in the specified directory\n",
    "dbutils.fs.rm(\"/FileStore/tables/\", recurse=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3197121113592625,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Remya_Vellakkadaparambu_Karthikeyan_ML",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
